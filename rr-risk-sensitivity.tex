\PassOptionsToPackage{unicode=true}{hyperref} % options for packages loaded elsewhere
\PassOptionsToPackage{hyphens}{url}
%
\documentclass[british,,doc,mask,floatsintext]{apa6}
\usepackage{lmodern}
\usepackage{amssymb,amsmath}
\usepackage{ifxetex,ifluatex}
\usepackage{fixltx2e} % provides \textsubscript
\ifnum 0\ifxetex 1\fi\ifluatex 1\fi=0 % if pdftex
  \usepackage[T1]{fontenc}
  \usepackage[utf8]{inputenc}
  \usepackage{textcomp} % provides euro and other symbols
\else % if luatex or xelatex
  \usepackage{unicode-math}
  \defaultfontfeatures{Ligatures=TeX,Scale=MatchLowercase}
\fi
% use upquote if available, for straight quotes in verbatim environments
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
% use microtype if available
\IfFileExists{microtype.sty}{%
\usepackage[]{microtype}
\UseMicrotypeSet[protrusion]{basicmath} % disable protrusion for tt fonts
}{}
\IfFileExists{parskip.sty}{%
\usepackage{parskip}
}{% else
\setlength{\parindent}{0pt}
\setlength{\parskip}{6pt plus 2pt minus 1pt}
}
\usepackage{hyperref}
\hypersetup{
            pdftitle={Incentives for a safe publication option from a risk sensitivity perspective},
            pdfkeywords={Publication bias, Registered Reports, hypothesis testing},
            pdfborder={0 0 0},
            breaklinks=true}
\urlstyle{same}  % don't use monospace font for urls
\usepackage{graphicx,grffile}
\makeatletter
\def\maxwidth{\ifdim\Gin@nat@width>\linewidth\linewidth\else\Gin@nat@width\fi}
\def\maxheight{\ifdim\Gin@nat@height>\textheight\textheight\else\Gin@nat@height\fi}
\makeatother
% Scale images if necessary, so that they will not overflow the page
% margins by default, and it is still possible to overwrite the defaults
% using explicit options in \includegraphics[width, height, ...]{}
\setkeys{Gin}{width=\maxwidth,height=\maxheight,keepaspectratio}
\setlength{\emergencystretch}{3em}  % prevent overfull lines
\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}
\setcounter{secnumdepth}{0}

% set default figure placement to htbp
\makeatletter
\def\fps@figure{htbp}
\makeatother

% Manuscript styling
\usepackage{upgreek}
\captionsetup{font=singlespacing,justification=justified}

% Table formatting
\usepackage{longtable}
\usepackage{lscape}
% \usepackage[counterclockwise]{rotating}   % Landscape page setup for large tables
\usepackage{multirow}		% Table styling
\usepackage{tabularx}		% Control Column width
\usepackage[flushleft]{threeparttable}	% Allows for three part tables with a specified notes section
\usepackage{threeparttablex}            % Lets threeparttable work with longtable

% Create new environments so endfloat can handle them
% \newenvironment{ltable}
%   {\begin{landscape}\begin{center}\begin{threeparttable}}
%   {\end{threeparttable}\end{center}\end{landscape}}
\newenvironment{lltable}{\begin{landscape}\begin{center}\begin{ThreePartTable}}{\end{ThreePartTable}\end{center}\end{landscape}}

% Enables adjusting longtable caption width to table width
% Solution found at http://golatex.de/longtable-mit-caption-so-breit-wie-die-tabelle-t15767.html
\makeatletter
\newcommand\LastLTentrywidth{1em}
\newlength\longtablewidth
\setlength{\longtablewidth}{1in}
\newcommand{\getlongtablewidth}{\begingroup \ifcsname LT@\roman{LT@tables}\endcsname \global\longtablewidth=0pt \renewcommand{\LT@entry}[2]{\global\advance\longtablewidth by ##2\relax\gdef\LastLTentrywidth{##2}}\@nameuse{LT@\roman{LT@tables}} \fi \endgroup}

% \setlength{\parindent}{0.5in}
% \setlength{\parskip}{0pt plus 0pt minus 0pt}

% Overwrite redefinition of paragraph and subparagraph by the default LaTeX template
% See https://github.com/crsh/papaja/issues/292
\makeatletter
\renewcommand{\paragraph}{\@startsection{paragraph}{4}{\parindent}%
  {0\baselineskip \@plus 0.2ex \@minus 0.2ex}%
  {-1em}%
  {\normalfont\normalsize\bfseries\itshape\typesectitle}}

\renewcommand{\subparagraph}[1]{\@startsection{subparagraph}{5}{1em}%
  {0\baselineskip \@plus 0.2ex \@minus 0.2ex}%
  {-\z@\relax}%
  {\normalfont\normalsize\itshape\hspace{\parindent}{#1}\textit{\addperi}}{\relax}}
\makeatother

% \usepackage{etoolbox}
\makeatletter
\patchcmd{\HyOrg@maketitle}
  {\section{\normalfont\normalsize\abstractname}}
  {\section*{\normalfont\normalsize\abstractname}}
  {}{\typeout{Failed to patch abstract.}}
\patchcmd{\HyOrg@maketitle}
  {\section{\protect\normalfont{\@title}}}
  {\section*{\protect\normalfont{\@title}}}
  {}{\typeout{Failed to patch title.}}
\makeatother

\usepackage{xpatch}
\makeatletter
\xapptocmd\appendix
  {\xapptocmd\section
    {\addcontentsline{toc}{section}{\appendixname\ifoneappendix\else~\theappendix\fi\\: #1}}
    {}{\InnerPatchFailed}%
  }
{}{\PatchFailed}
\keywords{Publication bias, Registered Reports, hypothesis testing}
\usepackage{csquotes}
\usepackage{float}
\usepackage{framed}
\usepackage{caption}
\usepackage{setspace}
\usepackage{amsmath}
\usepackage{wrapfig}
\captionsetup[figure]{font={stretch=1, small}, skip=10pt}
\captionsetup[textbox]{name=Box,labelsep=period,labelfont=it}
\newfloat{textbox}{thp}{lop}
\floatname{textbox}{Box}
\usepackage[most]{tcolorbox}
\definecolor{electricviolet}{rgb}{0.56, 0.0, 1.0}
\ifnum 0\ifxetex 1\fi\ifluatex 1\fi=0 % if pdftex
  \usepackage[shorthands=off,main=british]{babel}
\else
  % load polyglossia as late as possible as it *could* call bidi if RTL lang (e.g. Hebrew or Arabic)
  \usepackage{polyglossia}
  \setmainlanguage[variant=british]{english}
\fi

\title{Incentives for a safe publication option from a risk sensitivity perspective}
\author{Anne M. Scheel\textsuperscript{1}, Leo Tiokhin\textsuperscript{1}, \& Daniël Lakens\textsuperscript{1}}
\date{}


\shorttitle{Risk sensitivity in academic publishing}

\authornote{

Correspondence concerning this article should be addressed to Anne M. Scheel, Den Dolech 1, Atlas 9.417, 5600 MB, Eindhoven, The Netherlands. E-mail: \href{mailto:a.m.scheel@tue.nl}{\nolinkurl{a.m.scheel@tue.nl}}

}

\affiliation{\vspace{0.5cm}\textsuperscript{1} Eindhoven University of Technology}

\abstract{%
xxx Abstract xxx
}



\begin{document}
\maketitle

\texttt{TO\ DO:}

\begin{itemize}
\tightlist
\item
  General introduction describing the problem of publication bias and questionable research practices (QRPs)

  \begin{itemize}
  \tightlist
  \item
    Publication bias: positive results are more likely to get published than negative results; can happen due to reviewer bias (Greenwald, 1975; evidence: Mahoney, 1977; Atkinson, Furlong, \& Wampold, 1982) or file-drawering (Rosenthal, 1979; evidence: Franco, Malhotra, \& Simonovits, 2014, 2016)
  \item
    QRPs: exploiting undisclosed flexbility in data collection and analysis to obtain more desirable results (Simmons, Nelson, \& Simonsohn, 2011; evidence: John, Loewenstein, \& Prelec, 2012; Agnoli, Wicherts, Veldkamp, Albiero, \& Cubelli, 2017; Fiedler \& Schwarz, 2016; Fraser, Parker, Nakagawa, Barnett, \& Fidler, 2018). QRPs inflate the error rates of statistical tests, typically the false-positive rate
  \item
    consequence of publication bias and QRPs: the literature in psychology is excessively (\(>90\%\)) positive (Fanelli, 2010; Scheel, Schijen, \& Lakens, 2021; Sterling, 1959; Sterling, Rosenbaum, \& Weinkam, 1995) and unreliable (Wacholder, Chanock, Garcia-Closas, El ghormli, \& Rothman, 2004; evidence: Nosek et al., 2022)
  \end{itemize}
\item
  Reform efforts to address the problem:

  \begin{itemize}
  \tightlist
  \item
    preregistration to reduce QRPs (Lakens, 2019; Nosek, Ebersole, DeHaven, \& Mellor, 2018; Wagenmakers, Wetzels, Borsboom, van der Maas, \& Kievit, 2012)
  \item
    various journals of negative results to reduce publication bias (these never seem to be successful though and always shut down after a while; add examples/references)
  \item
    \textbf{Registered Reports} to reduce QRPs and publication bias at the same time (most powerful reform proposal to date)
  \end{itemize}
\end{itemize}

Registered Reports are an alternative publication format in which the review process is split in two stages:
At Stage 1, reviewers evaluate a pre-study protocol containing research questions, hypotheses, and planned methods of a proposed study.
In case of a positive decision, the journal provides authors with an in-principle acceptance and commits to publishing the eventual report regardless of the direction of the results.
Once authors have collected and analysed the data and written up the results, the final report is submitted to a second review stage, but this time only to ensure that the study was carried out as planned, that the data pass any pre-specified quality checks, and that authors' conclusions are justified by the evidence.

By moving the publication decision to a time point before results are known, Registered Reports provide a powerful protection against publication bias (publication is results-independent by design) and remove one important incentive for authors to use QRPs.
The remaining risk of QRPs is minimised by the two-stage review process, in which the Stage-1 protocol acts as a preregistration and reviewers' task during Stage-2 review is to flag any deviations from it.
The format was first launched in 2013 at the journal \emph{Cortex} (Chambers, 2013) and is now offered by over 300 journals, predominantly in the social and life sciences (see \url{cos.io/rr}).
By 2021, nearly 600 Registered Reports had been published (Chambers \& Tzavella, 2021).
Initial evidence shows that published Registered Reports have a substantially lower rate of positive results than regular articles in psychology (\(44\%\) versus \(96\%\), Scheel et al., 2021) and psychology, neuroscience, and the biomedical sciences (Allen \& Mehler, 2019), and are judged to be of higher quality (Soderberg et al., 2021).

Being a powerful bias-prevention tool that is increasingly popular, it is important to develop a better understanding of when, where, and by whom Registered Reports are most likely to be used.
First, such knowledge can help identify research areas in which the format is unlikely to gain traction by itself and anticipate the need for further intervention (e.g., via policy) when there is a demand for unbiased results.
Second, understanding when researchers' choice between Registered Reports and the standard publication route is likely to be influenced by factors that also influence the eventual results (e.g., the prior probability of the tested hypotheses) is important for meta-scientific studies that compare published studies in both formats and must take such confounds into account (e.g., Scheel et al., 2021).
Such confounds could also lead to a situation in which Registered Reports become associated with certain types of results (e.g., negative results) and devalued if these results are deemed less interesting or important by the research community, making the format unsustainable in the long run. \texttt{To\ do:\ add\ note\ that\ this\ is\ likely\ what\ happened\ to\ several\ "journals\ of\ negative\ results"\ that\ shut\ down\ due\ to\ lack\ of\ interest.}
The goal of this chapter is to shed light on these questions by studying the potential impact of a key feature of Registered Reports: The results-independent publication guarantee as an incentive for authors.

\hypertarget{registered-reports-as-a-low-risk-publication-option}{%
\subsection{Registered Reports as a low-risk publication option}\label{registered-reports-as-a-low-risk-publication-option}}

Registered Reports serve the scientific community and other consumers of the scientific literature by protecting against publication bias and QRPs.
But they are also designed to \enquote{serve the interests of individual scientists} (p.~12, Chambers \& Tzavella, 2021) by providing a publication guarantee irrespective of the study results.
As such, Registered Reports make use of existing incentive structures in academia and do not rely on changes in norms or policy (in contrast to other reforms such as preregistration).

Peer-reviewed publications are a central currency for academic researchers, both in terms of publication quantity and publication impact (Müller, 2014; van Dalen \& Henkens, 2012).
In the standard publication model, researchers face uncertainty about whether and where they will be able to publish the results of their study. Translated into currency terms, the payoff a researcher receives for conducting a study can vary extremely:
from near zero when the resulting manuscript is rejected by all consulted journals (or when the author file-drawers the study because the chances of success seem too low to justify the costs of repeated submissions and revisions) to an extremely high, perhaps career-making amount when a manuscript is published in a very high-impact journal like \emph{Nature} or \emph{Science}.
In other words, success in the standard system is highly variable and highly volatile since it hinges on the one factor that is supposed to be outside of researchers' control --- the study results.
This unfortunate combination can be excessively stressful for researchers (especially junior scientists without secure positions) and tempt them to hype, spin, or even fabricate their results.

Compared to this, Registered Reports are a relatively safe, stress-free alternative because authors receive a results-independent publication guarantee before investing in data collection or analysis.
As Registered-Reports inventor Chris Chambers put it in a recent talk (\href{https://youtu.be/FiVI3cwVMZI?list=PLChfyH8TVDGmYENpXUDPaeeq2SLh8q9dt\&t=1047}{September 2021}):

\begin{quote}
And the second main benefit, the one that really is the main big one, the big draw, is that as a researcher you can get your paper accepted before you even start your research and regardless of how the results turn out in the end. So no more playing the \emph{p}-value lottery, gambling on certain results going a certain way, otherwise you won't have your PhD or you won't get your next fellowship or your next grant\(\,\)---\(\,\)takes all of that pointless, and I think quite foolish, gambling out of the equation completely. (from minute 17:27)
\end{quote}

But would researchers ever choose the gamble over the safe publication?
Unless the net benefit of a Registered Report is always at least as valuable as the best possible outcome that could be achieved through the standard publication route, the answer is \enquote{probably yes}.
Authors deciding between Registered Reports and the standard publication route face the choice between a payoff with low variability (a relatively safe publication in the journal the Stage-1 protocol was submitted to) and a payoff with high variability (anywhere between no publication and a high-impact publication, or even several publications if the project yields enough \enquote{fodder}).
Situations like these are commonly termed \emph{decision-making under risk}.
\enquote{Risk} is defined as \enquote{unpredictable variation in the outcome of a behavior, with consequences for an organism's fitness or utility} (Winterhalder, Lu, \& Tucker, 1999, p. 302).
Organisms are \emph{risk sensitive} when they are not only sensitive to the mean outcomes of different behavioural options but also to their variance.

Framing authors' choice between Registered Reports and standard publications as risk-averse versus risk-prone behaviour allows us to examine the problem with Risk-Sensitivity Theory, a normative theory developed in behavioural ecology to explain the foraging behaviour of animals.
Risk-Sensitivity Theory was designed to determine the optimal food-acquisition strategy for an animal faced with a choice between a relatively safe (low-variance) food source and a risky (high-variance) source that sometimes yields large payoffs and sometimes small payoffs (or none at all).
Despite this initial narrow scope, Risk-Sensitivity Theory has proven itself as a powerful framework for explaining risk-sensitive behaviour in a wide range of situations and species, including humans (Kacelnik \& Bateson, 1996, 1997; Mishra, 2014).

\texttt{TO\ DO:}

\begin{itemize}
\tightlist
\item
  Explain that RST is superior to utility theory and can incorporate prospect theory (Mishra, 2014)
\item
  Better explain the evolutionary angle and why it matters
\end{itemize}

\hypertarget{goals-of-the-chapter}{%
\subsection{Goals of the chapter}\label{goals-of-the-chapter}}

In this chapter, a simulation model is used to explore how properties of academic careers and academic incentive structures that are relevant to risk sensitivity may affect the strategies of researchers choosing between Registered Reports and the standard publication format.
The research goal is to understand in which circumstances Registered Reports should be particularly attractive, particularly unattractive, or particularly prone to highly selective use.
The results of this analysis may help anticipate where the format is unlikely to take foot without additional changes to norms, incentives, or policy, and flag situations in which the results of published Registered Reports may be particularly difficult to compare to the normal literature.
The following sections outline central concepts of Risk-Sensitivity Theory, relate them to characteristics of academic careers, and describe an evolutionary simulation model in which their effects on researchers' risk-sensitive publication decisions are examined.

\hypertarget{conceptual-application-of-risk-sensitivity-theory-to-publication-decisions}{%
\section{Conceptual application of Risk-Sensitivity Theory to publication decisions}\label{conceptual-application-of-risk-sensitivity-theory-to-publication-decisions}}

This section describes general factors that affect the role of risk for individual's fitness and connects these factors to relevent elements of academic careers.
In this context, Risk-Sensitivity Theory's focus on reproductive fitness as the central outcome may be seen as misguided.
But although researchers do not forage, grow, reproduce, and die in the \emph{biological} sense (except in their role as human beings in general, of course), they undoubtedly are concerned with factors that influence 1) their survival and 2) the propagation of their traits in an \emph{academic} sense.
In applying Risk-Sensitivity Theory to researchers' publishing behaviour, we will therefore use a general notion of career success as the central outcome variable in place of reproductive fitness.
This decision does not imply that career success is the only or the proximal motivation for researchers' behaviour in practice, just as evolutionary theory does not imply that reproductive success is the only or the proximal motivation for human behaviour in everyday life.
\texttt{TO\ DO:}

\begin{itemize}
\tightlist
\item
  Refer back to a (not yet existing) section above to say that human decision making is a product of evolution
\item
  In addition, narrow bottlenecks between early-career and tenured positions in many academic disciplines inevitably create a selection pressure for behaviours that further researchers' career success (Smaldino \& McElreath, 2016).
\end{itemize}



\begin{figure}

{\centering \includegraphics[width=0.5\linewidth]{rr-risk-sensitivity_files/figure-latex/fitnessplot-1} 

}

\caption{Consequences of non-linear fitness functions. Payoffs \(b_-\), \(b_{safe}\), and \(b_+\) are converted into fitness with a diminishing (blue), linear (grey), or increasing (red) returns function.}\label{fig:fitnessplot}
\end{figure}

\hypertarget{non-linear-fitness-functions}{%
\paragraph{Non-linear fitness functions}\label{non-linear-fitness-functions}}

The first and perhaps most ubiquitous factor leading individuals to be risk sensitive are non-linear relationships between the outcomes of an individual's behaviour (e.g., harvested food items, publications) and its reproductive success (Kacelnik \& Bateson, 1997).
Consider two options, \(O_{safe}\) and \(O_{risky}\).
\(O_{safe}\) always gives the same payoff \(b_{safe}\), whereas \(O_{risky}\) gives either a low payoff \(b_-\) or a high payoff \(b_+\), each with probability \(\frac{1}{2}\).
When \(b_{safe} = \frac{(b_- + b_+)}{2}\), \(O_{safe}\) and \(O_{risky}\) have the same expected payoff.
However, we would only expect an individual to be indifferent between the two options if the consequences of their payoffs for the individual's fitness are linear.
When the function relating payoffs to utility is instead convex or concave (yielding increasing or diminishing returns, respectively), the expected utility of \(O_{safe}\) and \(O_{risky}\) will differ and shift the individual's preference towards risk proneness or risk aversion.
An illustration of this example is shown in Figure~\ref{fig:fitnessplot}:
While the payoffs \(b_-\), \(b_{safe}\), and \(b_+\) are equidistant on the x-axis, \(b_{safe}\) is associated with greater fitness than the average of \(b_-\) and \(b_+\) when the fitness function is concave, and with less fitness when the fitness function is convex.
In other words, \(O_{safe}\) has greater expected fitness than \(O_{risky}\) when returns are diminishing, and \(O_{risky}\) has greater expected fitness than \(O_{safe}\) when returns are increasing.

Non-linear relationships are arguably the norm in the natural world and linear relationships the exception.
This plausibly holds for academia as well, where the effect of publication success on researchers' career success might change over time:
For early-career researchers, small increases in the number or impact of publications may have an accelerated effect on career success, whereas established professors may care little about any one additional publication on their record.



\begin{figure}

{\centering \includegraphics[width=0.6\linewidth]{rr-risk-sensitivity_files/figure-latex/varianceplot-1} 

}

\caption{Survival thresholds. When fitness drops to zero below the low threshold (dashed line), individuals should be risk-averse because the outcomes of the low-risk option (narrow curve) are guaranteed to lie above the threshold and the outcomes of the high-risk option (wide cuve) have a non-negligible risk of falling below the threshold. When fitness drops to zero below the high threshold (dotted line), individuals should be risk-prone because only the high-risk option provides a chance of passing the threshold.}\label{fig:varianceplot}
\end{figure}

\hypertarget{survival-thresholds-and-competition}{%
\paragraph{Survival thresholds and competition}\label{survival-thresholds-and-competition}}

A second important factor for risk-sensitive behaviour are thresholds for survival and reproduction (Hurly, 2003; Winterhalder et al., 1999).
Survival thresholds are cutoff points below which an individual's fitness drops to zero, for example due to starvation.
Risk-Sensitivity Theory predicts that an individual will be risk averse when the resources provided by a low-variance option are sufficient to meet the threshold and risk averse when they are not (Mishra, 2014).
For example, a hummingbird that needs to acquire a certain amount of calories to survive the night will prefer a low-risk food source if this option's expected payoff is above the threshold, but avoid the low-risk source if only a higher-risk source provides a chance of survival.
One such situation is depicted in Figure~\ref{fig:varianceplot}.

Although comparable cutoff points in academic careers may have somewhat less severe consequences, they certainly exist:
Amount and impact of a researcher's publications are common and often explicit criteria in decisions that are central to the individual's career, such as whether they will be awarded a PhD, whether they will receive grant funding, whether they will be offered a tenure-track position, or whether they will be granted tenure.
In some of these situations, the cutoff points are absolute and thus resemble survival thresholds in the biological sense, for example PhD-programme regulations that determine a minimal amount of peer-reviewed publications for a candidate to be awarded with a PhD, or tenure contracts that specify minimal publication targets.
In other situations, the cutoff points are relative and depend on the number of eligible candidates, for example when grant funding is awarded to the 10 highest-ranked research proposals or a job is offered to the best candidate from a pool of applicants.
In cases like these, one individual's success diminishes the chances of another --- they represent \emph{competition}.
In the following, survival thresholds and competition will be treated as separate concepts to examine their differential effects on researchers' publication behaviour.

\hypertarget{number-of-decision-events-before-evaluation}{%
\paragraph{Number of decision events before evaluation}\label{number-of-decision-events-before-evaluation}}

A final risk-relevant factor considered here is the number of decision events taking place before an individual's fitness is evaluated.
When a risky option is chosen repeatedly, the average of the accumulating payoffs gets closer and closer to the long-run expected payoff.
This means that the danger of loosing out completely by only acquiring the lowest possible payoff of the risky option diminishes, making the risky option relatively more attractive.
However, this relationship only holds for repeated decision events \emph{before} an individual's fitness is evaluated.
When fitness is evaluated after a single decision event, a risky option is more likely to yield an extreme outcome that translates to zero fitness (i.e., death or an ultimate failure to reproduce).

In situations like this, when a single risky decision might cost an individual's life or offspring, average fitness is best described by the geometric mean instead of the arithmetic mean (Haaland, Wright, \& Ratikainen, 2019).
The geometric mean is more sensitive to variance because it is multiplicative, capturing the fact that one failure to reproduce can end a genetic lineage.
This circumstance has been shown to produce bet-hedging:
Risk-averse strategies may be more adaptive across many generations even when more risk-prone strategies produce better outcomes in any one generation, simply because the latter are also more likely to lead to extinction by sheer bad luck (Haaland et al., 2019).
While average fitness across generations is best represented with the geometric mean, average fitness \emph{within} a generation is better captured by the arithmetic mean, reflecting the additive accumulation of payoffs from decision events before fitness is evaluated.
Therefore, as the number of decision events per generation (i.e., before fitness is evaluated) increases, the variance-sensitive geometric mean of acquired payoffs becomes relatively less important and the less variance-sensitive arithmetic mean becomes more important.
Consequently, individuals' behaviour should switch from relative risk-aversion to relative risk-proneness.

In the academic world, decision events before fitness is evaluated (\enquote{per generation}) could seen as the time and resources a researcher has available for producing publications before a relevant selection event like those mentioned in the previous section (award of a PhD or grant, job application, tenure decision) is made.
This parameter likely varies with career stage:
A PhD student usually has three to four years to achieve the required publication output, a postdoc may work on a short-term contract of two years or even one year (after which their CV must be strong enough for the next application), and an assistant professor may have around seven years for receiving tenure.
In addition, career progress often comes with greater research funds and, most importantly, the supervision of students and junior researchers whose efforts boost the supervisors' output (Müller, 2014).
As a second, orthogonal aspect, the amount of publishable research that can be achieved before a selection event may vary between research areas.
In some fields, data collection is fast and cheap, for example when experiments consist of short online questionnaires that are disseminated to large participant pools such as Amazon MTurk.
In other fields, data collection is very expensive and slow, for example in clinical fMRI studies on specific patient groups.
Irrespective of career stage, researchers in fields with fast and cheap data may thus be able to complete many more research cycles per time unit than researchers who use more expensive data.

Each of the risk-relevant factors described above\(\,\)---\(\,\)non-linear fitness functions, survival thresholds, competition, and number of decision events before evaluation\(\,\)---\(\,\)likely impacts researchers' decison strategies, including their choices between low-risk and high-risk publication options.
To better understand when a low-risk option like Registered Reports should be particularly attractive or unattractive, the individual and interactive effects of these factors are examined in a simulation model.

\hypertarget{simulation-model}{%
\section{Simulation model}\label{simulation-model}}

We develop an evolutionary agent-based model which simulates a population of researchers who test hypotheses, (attempt to) publish the results either as Registered Reports or as standard reports, accumulate the payoffs for successful publications, and pass their publication strategies on to the next generation of researchers.

\hypertarget{research-phase}{%
\paragraph{Research phase}\label{research-phase}}

Consider a population of \(n = 500\) researchers.
Each researcher has a fixed publication strategy \(s\), the so-called submission threshold.
In each round of the research phase, researchers randomly pick a hypothesis to test in a study.
Hypotheses are true with prior probability \(p\), which is uniformly distributed between 0 and 1.
Before testing their chosen hypothesis, a researcher compares the prior \(p\) of their hypothesis with their submission threshold \(s\).
When \(p < s\), the researcher chooses to play it safe and test the hypothesis in a Registered Report.
When \(p \geq s\), the researcher chooses to gamble and test the hypothesis in a normal study which is then submitted as a stardard report.

For simplicity, we assume that \(p\) is an ideal objective prior and that researchers' hypothesis tests are free from additional sources of error.
Thus, when a researcher tests hypothesis \(i\), they obtain a positive result with probability \(p_i\) and a negative result with probability \(1-p_i\).
If the researcher chose to submit a Registered Report, their study is published regardless of the result and the researcher receives a payoff \(b_{RR}\).
However, if the researcher chose to submit a standard report, they face rampant publication bias:
Only positive results are publishable as standard reports and yield a payoff \(b_{SR+}\), whereas negative results are rejected or file-drawered and only yield a minimal payoff \(b_{SR-}\).
For all variations of the model tested here, we assume that \(b_{SR-} < b_{RR} < b_{SR+}\).
This assumption reflects the following considerations:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Due to publication bias, negative results are less valuable than positive results in standard reports (\(b_{SR-} < b_{SR+}\)), for example because they do not lead to a publication at all, because only very low-impact journals are willing to publish them, or because getting them published requires a lot of extra effort (e.g., via frequent resubmissions following rejection or substantial revisions demanded by reviewers) that diminishes the net reward.
\item
  For these same reasons, Registered Reports are on average more valuable than standard reports with negative results (\(b_{SR-} < b_{RR}\)), for example because Registered Reports are offered by journals that may display publication bias and reject negative results in standard report submissions, or simply because Registered Reports do not need to be resubmitted or require more extensive revisions in case of a negative result.
\item
  On average, standard reports with positive results are more valuable than Registered Reports (\(b_{RR} < b_{SR+}\)), for example because most extremely high-impact journals do not (yet) offer Registered Reports, because not registering one's study \emph{a priori} makes it easier to spin the results into an attention-grabbing story, or because Registered Reports may require more effort due to their stricter quality criteria, lowering the net reward.
  While proponents of Registered Reports may argue that the format has such trememdous advantages that authors' resulting career benefits are superior to any alternative, this chapter is predicated on the assumption that most researchers currently do not share this view.
  Once this changes, the present investigation may happily become redundant.
\end{enumerate}

The whole research cycle\(\,\)---\(\,\)choosing a hypothesis, choosing a publication route by comparing its prior \(p\) to one's submission threshold \(s\), testing the hypothesis, and receiving payoff \(b_{RR}\) for a Registered Report or \(b_{SR-}\) or \(b_{SR+}\) for a positive and negative standard report, respectively\(\,\)---\(\,\)is repeated \(m\) times.

\hypertarget{evaluation-phase}{%
\paragraph{Evaluation phase}\label{evaluation-phase}}

At the end of the research phase, researchers are evaluated by translating their accumulated publication payoffs \(b_1 + b_2 + ... + b_m\) into fitness.
Fitness is calculated with a function characterised by exponent \(\epsilon\), which determines the shape of the function. \(\epsilon = 1\) yields a linear function, \(0 < \epsilon < 1\) yields a concave function with diminishing returns, and \(\epsilon > 1\) yields a convex function with increasing returns (see Figure~\ref{fig:fitnessplot}):

\begin{align}
fitness = (\sum_{i=1}^{m} b_i)^\epsilon
\end{align}

However, two situations may cause a researcher's fitness to fall to zero even when their accumulated payoffs are nonzero.
First, the sum of their payoffs may fall below an absolute survival threshold \(\delta\), for example when a researcher fails to meet an agreed publication target by the time their \enquote{tenure clock} runs out.
Thus, when \(\sum_{i=1}^{m} b_i < \delta\), \(fitness = 0\).
Second, the sum of their payoffs may fall below a relative threshold \(\gamma\), which reflects the intensity of competition for scarce resources such as research grants or positions.
\(\gamma\) is the proportion of the most productive researchers that are considered for reproduction.
When \(\gamma = 1\), all researchers in the population are considered for reproduction and their fitness is calculated according to Eq. 1.
When \(\gamma < 1\), the \((1 - \gamma)\) portion of researchers with the lowest sum of payoffs receives zero fitness and cannot reproduce.\footnote{The computer code of the simulation applies \(\gamma\) after fitness has been calculated according to the accumulated payoffs. This change has purely technical reasons and yields the same result as calculating fitness after \(\gamma\) has been applied to accumulated payoffs, since all fitness functions are monotonic increasing.}
For example, \(\gamma = 0.1\) means that only those researchers with accumulated payoffs in the top \(10\%\) of the population can reproduce, and the remaining \(90\%\) receives zero fitness.

\hypertarget{reproduction-phase}{%
\paragraph{Reproduction phase}\label{reproduction-phase}}

Finally, the researchers in the current population retire and a new (non-overlapping) generation of researchers is created.
A researcher in the new generation inherits their publication strategy (submission threshold) \(s\) from a researcher in the previous generation with the probability of the previous researcher's fitness (i.e., the new generation's submission thresholds are sampled with replacement from the previous generation, probability-weighted by fitness).
The new generation's submission thresholds are inherited with a small amount of random noise, such that \(s_{new} = s_{old} + w\) with \(w \sim R(\mu = 0, \sigma = 0.01)\).
This evolutionary dynamic of researchers passing on their traits to other researchers depending on their career success can be seen as reflecting mentorship and explicit teaching, such as when established professors advise their students to use the same strategies, or simply a generic social learning process in which successful researchers are more likely to be imitated by others.

\hypertarget{outcome-variables}{%
\subsubsection{Outcome variables}\label{outcome-variables}}

We study how the evolution of researchers' submission thresholds \(s\) is affected by the payoff parameters \(b_{RR}\), \(b_{SR-}\), and \(b_{SR+}\), by the shape of the fitness function determined by exponent \(\epsilon\), by the absolute survival threshold \(\delta\), by competition \(\gamma\), and by the number of research cycles per generation \(m\) (see Table 1 for an overview of the model parameters and their values considered in the simulation).
It is important to keep in mind that a researcher's submission threshold \(s\) is a \emph{strategy}, not an absolute decision\(\,\)---\(\,\)it determines \emph{how} the choice between Registered Reports and standard reports is made, not which format is chosen.
As such, \(s\) indicates the amount of risk a researcher is willing to take.
Very low values of \(s\) reflect risk proneness:
The researcher is willing to gamble and chooses the standard publication route for almost all hypotheses they encounter, using the Registered Reports route only for hypotheses that are virtually guaranteed to be false (and yield negative results).
Very high values of \(s\) reflect risk aversion:
The researcher is unwilling to risk a negative result in a standard report and studies almost all hypotheses they encounter in the Registered Reports format, reserving the standard publication route only for hypotheses that are virtually guaranteed to be true (and yield positive results).

The evolved values of \(s\) over many generations indicate the optimal strategy for a given set of parameter values.

\hypertarget{simulation-results}{%
\section{Simulation results}\label{simulation-results}}

When interpreting the results below, it is important to keep in mind that the analysed parameter values are inherently arbitrary.
Although the model parameters are chosen to capture important characteristics of real-world concepts, the parameter values do not represent real-world units.
The goal of this analysis is to understand the relative effects of the model parameters in a simplified artificial system, and thus the results are only meaningful in relation to each other.



\begin{figure}

{\centering \includegraphics[width=5.04in]{/zephyr/Documents/Uni/_projects/rr-model/plots/plot_evo} 

}

\caption{Evolution of submission threshold \(s\) with 3 different payoffs for Registered Reports (\(b_{RR}\)). Simulations are based on a population of \(n = 500\) researchers over 250 generations, with payoffs for standard reports fixed at 0 for negative results (\(b_{SR-} = 0\)) and 1 for positive results (\(b_{SR+} = 1\)), a linear fitness function \(\epsilon = 1\), one research cycle per generation (\(m = 1\)), no survival threshold (\(\delta = 0\)) and no competition (\(\gamma = 1\)). Each condition was run 10 times. Thin lines represent the median submission threshold of the population in each run, shaded areas represent the inter-quartile range of submission thresholds in the population in each run, thick lines represent the median of run medians per condition.}\label{fig:evoplot}
\end{figure}

The first generation of researchers in each simulation run is initialised with randomly distributed submission thresholds \(s\) (drawn from a uniform distribution {[}0--1{]}), which are then allowed to evolve over the subsequent generations.
All variations of the simulation model reported here were run with a population size of \(n = 500\) researchers over 250 generations and payoffs for negative and positive results in standard reports fixed at \(b_{SR-} = 0\) and \(b_{SR+} = 1\), respectively.
Figure~\ref{fig:evoplot} shows the effect of varying the payoffs for Registered Reports when the fitness function is linear (\(\epsilon = 1\)), with no survival threshold (\(\delta = 0\)) or competition (\(\gamma = 1\)), and one research cycle per generation (\(m = 1\)).
The overall pattern of results is unsurprising\(\,\)---\(\,\)the higher the payoff for Registered Reports, the more popular they become.
When \(b_{RR}\) is low, Registered Reports are unpopular and only used for the least probable hypotheses; when \(b_{RR}\) is high, Registered Reports are very popular and only hypotheses with extremely high priors are studied in standard reports.

In this very simple case illustrated here, evolved submission thresholds approximate the payoff for Registered Reports in each condition, indicating that the optimal submission threshold is always equal to \(b_{RR}\) (\(s_{optimal} = 0.2\) when \(b_{RR} = 0.2\), \(s_{optimal} = 0.5\) when \(b_{RR} = 0.5\), \(s_{optimal} = 0.8\) when \(b_{RR} = 0.8\)).
The reason behind this is the uniform distribution {[}0--1{]} of hypothesis priors and the payoff structure \(b_{SR-} = 0\) and \(b_{SR+} = 1\), which means that the expected payoff of a standard report is always equal to the prior of the tested hypothesis:

\begin{align}
E[b_{SR}] = p b_{SR+} + (1-p)b_{SR-} = p * 1 +  (1-p) * 0 = p
\end{align}

For example, testing a hypothesis with \(p = 0.2\) in a standard report would yield the expected payoff \(0.2 * 1 + 0.8 * 0 = 0.2\).
The optimal strategy is to submit a Registered Report whenever the expected payoff of a standard report is lower than the payoff for a Registered Report, \(E[b_{SR}] < b_{RR}\), and thus whenever \(p < b_{RR}\).
The strategy is optimal because it ensures that researchers always get the best of both worlds, minimising shortfalls when priors are (too) low and maximising winning chances when priors are (sufficiently) high.
For example, \(b_{RR} = 0.5\) is larger than \(E[b_{SR}]\) for all hypotheses with \(p < 0.5\) but lower than \(E[b_{SR}]\) for all hypotheses with \(p > 0.5\).
In this situation, researcheres who submit Registered Reports whenever \(p<0.5\) and standard reports whenever \(p>0.5\) protect themselves against losing a bad bet by instead taking the fixed payoff \(b_{RR} = 0.5\) but always play a good bet and thus maximise their chances of winning \(b_{SR+} = 1\).
Every alternative is inferior in the long run because researchers with \(s > b_{RR}\) lose out on increased chances of publishing a standard report and researchers with \(s < b_{RR}\) take unnecessary risks and go empty-handed too often.



\begin{figure}

{\centering \includegraphics[width=0.65\linewidth]{/zephyr/Documents/Uni/_projects/rr-model/plots/plot_b_e} 

}

\caption{Effect of fitness functions on evolved submission thresholds. Shown are median submission thresholds in the final (\(250^{th}\)) generations of 50 runs for different values of \(b_{RR}\) (x-axis) and different fitness functions (characterised by exponent \(\epsilon\)), with one research cycle per generation (\(m = 1\)), no survival threshold (\(\delta = 0\)) and no competition (\(\gamma = 1\)). Fitness functions with \(\epsilon = 0.2\) and \(\epsilon = 0.5\) (blue lines) are concave with diminishing returns, functions with \(\epsilon = 2\) and \(\epsilon = 5\) (red lines) are convex with increasing returns, and the function with \(\epsilon = 1\) (grey line) is linear. Small dots represent median \(s\) of the final generation in each run, large dots represent the median of these 50 run medians per condition. Error bars represent the \(95\%\) capture probability around the median of medians.}\label{fig:epsilonplot}
\end{figure}

\hypertarget{non-linear-fitness-functions-1}{%
\subsection{Non-linear fitness functions}\label{non-linear-fitness-functions-1}}

With this basic understanding of the payoff structure in hand, we can take a look at what happens when payoffs have non-linear consequences for researchers' fitness.
Figure~\ref{fig:epsilonplot} contrasts the effects of two diminishing fitness functions (\(\epsilon = 0.2\) and \(\epsilon = 0.5\), shown in blue shades) and two increasing fitness functions (\(\epsilon = 2\) and \(\epsilon = 5\), shown in red shades) with a linear function (\(\epsilon = 1\), grey line) for different payoffs for Registered Reports.
The grey line for \(\epsilon = 1\) represents the already familiar situation from Figure~\ref{fig:evoplot} above:
When the fitness function is linear, the optimal strategy is \(s_{optimal} = b_{RR}\), making Registered Reports relatively popular when they are worth more than 0.5 and relatively unpopular when they are worth less than 0.5.
Non-linear fitness functions change this picture.
When additional payoffs yield diminishing returns (\(\epsilon <1\)), Registered Reports become more attractive even when they are worth less than half of published (positive) standard reports.
This is because concave functions \enquote{shrink} the difference between moderate and high payoffs relative to the difference between low and moderate payoffs (as illustrated in Figure~\ref{fig:fitnessplot}).
Conversely, when additional payoffs yield increasing returns (\(\epsilon > 1\)), Registered Reports are unattractive unless their payoffs are almost as large as those for published standard reports because convex functions increase the difference between moderate and high payoffs relative to low versus moderate payoffs.

When different fitness functions are taken to reflect different career stages\(\,\)---\(\,\)such that senior researchers' returns on career success per publication (or per increment of publication impact) are diminishing and those of early-career researchers are increasing\(\,\)---\(\,\)this pattern suggests that Registered Reports should be more attractive for senior researchers and a tough sell for early-career researchers.
This observation is interesting because it seems at odds with preliminary evidence suggesting that Registered Reports may be more likely to have early-career researchers as first authors than standard reports (Chambers \& Tzavella, 2021).
One explanation for such data (if robust) could be that the effect of concave versus convex fitness functions is swamped out by factors unrelated to risk sensitivity (e.g., younger researchers being more likely to adopt new methods).
However, as we will see below, the effects of different fitness functions are not always as straightforward as in the simple case illustrated in Figure~\ref{fig:epsilonplot} but produce different results in interaction with other risk-related factors.



\begin{figure}
\includegraphics[width=0.5\linewidth]{/zephyr/Documents/Uni/_projects/rr-model/plots/plot_m} \caption{Effect of research cycles per generation on evolved submission thresholds. Shown are median evolved submission thresholds (\(s\)) after 250 generations in 50 runs (tile colour represents the median of 50 run medians) for varying numbers of research cycles per generation (\(m\), y-axis), different values of \(b_{RR}\) (x-axis), and different fitness functions (characterised by exponent \(\epsilon\)).}\label{fig:mplot}
\end{figure}

\hypertarget{number-of-decision-events-before-evaluation-1}{%
\subsection{Number of decision events before evaluation}\label{number-of-decision-events-before-evaluation-1}}

The analyses discussed so far focused on the simple case of one research cycle (or decision event) per generation, meaning that researchers' fitness was calculated based on only a single payoff from one single study.
As discussed above, increasing numbers of decision events prior to evalution may make individuals more risk-prone because single negative outcomes are less catastrophic for reproduction (Haaland et al., 2019).
However, Figure~\ref{fig:mplot} shows that the effect of increasing numbers of research cycles per generation (\(m\)) interacts with the shape of the fitness function:
Moving up on the y-axis of each panel, we see that submission thresholds are decreasing (indicating risk proneness) only in the top panel (\(\epsilon = 0.2\)) but stay constant in the middle panel (\(\epsilon = 1\)) and even \emph{increase} in the bottom panel (\(\epsilon = 5\)).
Why does \(m\) appear to have opposite effects for diminishing and increasing fitness functions?
To understand this pattern, it helps to first consider only the bottom row of each panel, where \(m = 1\).
These three rows contain the same data as the top, middle, and bottom curves in Figure~\ref{fig:epsilonplot} and show risk aversion when \(\epsilon = 0.2\) (i.e., Registered Reports are attractive even when they yield a low payoff), risk proneness when \(\epsilon = 5\) (Registered Reports are unattractive even when they yield a high payoff), and a linear strategy \(s_{optimal} = b_{RR}\) when \(\epsilon = 1\).
From this starting point, the two panels with non-linear fitness functions start to approximate the linear case as \(m\) increases.
This dynamic reflects the idea that fitness is better captured by the geometric mean when \(m\) is low, and better captured by the arithmetic mean when \(m\) is high (Haaland et al., 2019).

To use an illustrating example, consider two researchers with extreme submission strategies:
Emma conducts only Registered Reports (\(s_{Emma} = 1\)) and Gordon conducts only standard reports (\(s_{Gordon} = 0\)).
The payoff for Registered Reports is fixed at \(b_{RR} = 0.5\).
After one research cycle, Emma receives a payoff of 0.5 and Gordon receives either 0 or 1.
When fitness is calculated after this one round with \(\epsilon = 0.2\), Emma's fitness is \(b_{Emma}^{\epsilon} = \frac{1}{2}^{\frac{1}{5}} = 0.87\), and Gordon's fitness is either \(b_{Gordon-}^{\epsilon} = 0^{\frac{1}{5}} = 0\) or \(b_{Gordon+}^{\epsilon} = 1^{\frac{1}{5}} = 1\).
In a population of Emmas and Gordons, lucky Gordons who got a positive result have a narrow fitness advantage over all Emmas (1 versus 0.87), while unlucky Gordons lose to all Emmas by a wide margin (0 versus 0.87).
Since there are twice as many Emmas as lucky Gordons, the Emma strategy is quite successful.

Now consider the same scenario with 4 research cycles before fitness is calculated.
Emmas receive the same payoff in every round and accumulate \(\frac{1}{2} * 4 = 2\).
Lucky Gordons (who win every time) accumulate a total payoff of \(1*4 = 4\), while unlucky Gordons (who lose every time) again receive 0 total payoff.
Now, however, the probabilistic outcomes over 4 rounds lead to more versions of Gordon, including average Gordons (who win half of the time and lose half of the time) who accumulate the same total payoff as Emmas \((\frac{1}{2}*0 + \frac{1}{2}*1)*4 = 2\).
This translates into fitness values of 0 for unlucky Gordons, \(2^{\frac{1}{5}} = 1.15\) for Emmas and average Gordons, and \(4^{\frac{1}{5}} = 1.32\) for lucky Gordons.
The Emma strategy still yields an enormous advantage compared to unlucky Gordons and only a small disadvantage compared to lucky Gordons.
But this time, there are fewer Gordons who are less successful than Emmas because Emmas now share their place with average Gordons, meaning that the relative fitness advantage of the Emma strategy decreases.
As the number of research cycles per generation grows, the law of large numbers dictates that more Gordons achieve average total payoffs and fewer Gordons achieve extreme total payoffs (winning 32 times in a row is much less probable than winning 4 times in a row), which reduces the width of the Gordon distribution until it approximates the Emma distribution.

When the fitness function is increasing (\(\epsilon = 5\)), the overall effect of increasing values of \(m\) is identical, with the only difference that Emmas are initially disadvantaged (because their fitness distance to the lucky half of Gordons is much greater than than to the unlucky Gordons).
With larger \(m\), more and more Gordons receive average total payoffs and share Emma's disadvantaged position (decreasing Emma's relative disadvantage), until the Gordon distribution is again virtually equal to the Emma distribution.
These results show that rather than causing absolute risk aversion, increasing values of \(m\) simply swamp out the effect of \(\epsilon\) and reduce the effects of all fitness functions to the linear case.
Consequently, the top rows (\(m = 32\)) of the top and bottom panels in Figure~\ref{fig:mplot} resemble the stable pattern across all \(m\) shown in the middle panel.

A reference to Figure~\ref{fig:deltaplot}.



\begin{figure}
\includegraphics[width=1\linewidth]{/zephyr/Documents/Uni/_projects/rr-model/plots/plot_delta} \caption{Figure note).}\label{fig:deltaplot}
\end{figure}

\hypertarget{survival-thresholds}{%
\subsection{Survival thresholds}\label{survival-thresholds}}

A reference to Figure~\ref{fig:competitionplot}.



\begin{figure}
\includegraphics[width=1\linewidth]{/zephyr/Documents/Uni/_projects/rr-model/plots/plot_comp} \caption{Figure note).}\label{fig:competitionplot}
\end{figure}

\hypertarget{competition}{%
\subsection{Competition}\label{competition}}

\hypertarget{measures-and-coding-procedure}{%
\subsection{Measures and coding procedure}\label{measures-and-coding-procedure}}

Print settings from the script \enquote{utilitycurves\_plot.R}:

payoff\_RR is \(0.60\) and e\_low is 0.25.

\hypertarget{discussion}{%
\section{Discussion}\label{discussion}}

\begin{itemize}
\tightlist
\item
  Brief recap of results
\item
  Implications of results

  \begin{itemize}
  \tightlist
  \item
    cautious mapping of model factors to real-world situations
  \item
    potential implications for meta-science
  \item
    potential implications for policy
  \end{itemize}
\end{itemize}

\hypertarget{limitations}{%
\subsection{Limitations}\label{limitations}}

\begin{itemize}
\item
  Narrow focus on one specific (and highly stylised) difference between Registered Reports and standard reports; there are many others. Model ignores a myriad other factors that influences who chooses Registered Reports for which studies when
\item
  Concept of publication bias as filtering positive results of hypothesis tests (and the respective connection to hypothesis priors such that high priors --\textgreater{} better) is cartoonish and not entirely accurate for the simple reason that positive results of trivial (or otherwise boring) hypotheses are usually not highly valued (also, this approach only focuses on hypothesis testing, which is widely used in psychology but by far not the only means of doing science).
  A more valid solution may be the concept of publication bias as favouring belief-shifting results presented by Gross and Bergstrom (2021).
  Adapting the model presented here to capture this concept of bias could be an interesting future direction.
  However, the present version of the model also allows a conservative interpretation in which the prior probability of hypotheses simply reflects authors' predictions of the eventual publication value of different research questions.
  This interpretation is still concordant with Registered Reports and standard reports differing in risk, because the publication value of standard reports certainly depends more strongly on the study results than the publication value of Registered Reports (even if not in the simplistic sense of positive hypothesis tests having higher value).
\end{itemize}

\hypertarget{future-directions}{%
\subsection{Future directions}\label{future-directions}}

\hypertarget{ability-based-risk-taking}{%
\paragraph{Ability-based risk taking}\label{ability-based-risk-taking}}

The model presented in this chapter only considers the effects of situational factors on individuals' risk sensitivity.
However, risk sensitivity can also be influenced by individual differences, so that individuals with traits or abilities that increase their expected payoff from a risky option (e.g., traits that increase their winning chances or the payoff when winning, or that buffer losses) should be more risk-prone (Barclay, Mishra, \& Sparks, 2018).
Such factors may be important to consider in the context of research and publication practices.
For example, researchers who are better at choosing research questions that are likely to result in high-impact publications (e.g., through talent or experience) may find Registered Reports less attractive.
As a more nefarious version of this idea, Registered Reports may be relatively unpopular among researchers who are more willing or able to use questionable research practices (or even fraud) to obtain publishable or impactful results.

\hypertarget{registered-reports-and-post-publication-peer-review}{%
\paragraph{Registered Reports and post-publication peer review}\label{registered-reports-and-post-publication-peer-review}}

The post-publication peer review platform \emph{Peer Community In} (PCI) recently launched a new model of Registered Reports (PCI Registered Reports) in which authors are no longer tied to a specific journal.
PCI offers authors the regular process of stage-1 and stage-2 review, the end result of a successful submission is \enquote{only} a preprint with a so-called \enquote{recommendation} from PCI.
Authors can subsequently publish their manuscript in one of several journals who partnered with PCI and either rely on the PCI review process alone or offer a streamlined review process for PCI-recommended preprints, or they can submit to any other journal as if their manuscript were a standard report.
This innovation gives Registered-Reports authors significantly more freedom to capitalise on the results of their study because a submission to PCI Registered Reports does not preclude the chance of a high-impact publication.
PCI Registered Reports thus constitute a signficant change to the relative incentives and risk structure of Registered Reports compared to standard reports that merits a closer investigation in the future.

\hypertarget{conclusion}{%
\subsection{Conclusion}\label{conclusion}}

\hypertarget{disclosures}{%
\subsection{Disclosures}\label{disclosures}}

\hypertarget{data-materials-and-online-resources}{%
\subsubsection{Data, materials, and online resources}\label{data-materials-and-online-resources}}

This manuscript was created using RStudio (1.2.5019, RStudio Team, 2019) and R (Version 3.6.0; R Core Team, 2019) and the R-packages \emph{bookdown} (Version 0.24; Xie, 2016), \emph{ggplot2} (Version 3.3.5; Wickham, 2016), \emph{here} (Version 1.0.1; Müller, 2017), \emph{knitr} (Version 1.37; Xie, 2015), \emph{papaja} (Version 0.1.0.9997; Aust \& Barth, 2018), \emph{rmarkdown} (Version 2.12; Xie, Allaire, \& Grolemund, 2018), \emph{stringr} (Version 1.4.0; Wickham, 2019), and \emph{tinylabels} (Version 0.2.3; Barth, 2022).

\hypertarget{references}{%
\section{References}\label{references}}

\setlength{\parindent}{-0.2in}
\setlength{\leftskip}{0.2in}

\hypertarget{refs}{}
\leavevmode\hypertarget{ref-Agnoli2017}{}%
Agnoli, F., Wicherts, J. M., Veldkamp, C. L. S., Albiero, P., \& Cubelli, R. (2017). Questionable research practices among italian research psychologists. \emph{PLOS ONE}, \emph{12}(3), e0172792. \url{https://doi.org/10.1371/journal.pone.0172792}

\leavevmode\hypertarget{ref-Allen2019}{}%
Allen, C., \& Mehler, D. M. A. (2019). Open science challenges, benefits and tips in early career and beyond. \emph{PLOS Biology}, \emph{17}(5), e3000246. \url{https://doi.org/10.1371/journal.pbio.3000246}

\leavevmode\hypertarget{ref-Atkinson1982}{}%
Atkinson, D. R., Furlong, M. J., \& Wampold, B. E. (1982). Statistical significance, reviewer evaluations, and the scientific process: Is there a (statistically) significant relationship? \emph{Journal of Counseling Psychology}, \emph{29}(2), 189--194. \url{https://doi.org/10.1037/0022-0167.29.2.189}

\leavevmode\hypertarget{ref-R-papaja}{}%
Aust, F., \& Barth, M. (2018). \emph{papaja: Create APA manuscripts with R Markdown}.

\leavevmode\hypertarget{ref-Barclay2018}{}%
Barclay, P., Mishra, S., \& Sparks, A. M. (2018). State-dependent risk-taking. \emph{Proceedings of the Royal Society B: Biological Sciences}, \emph{285}(1881), 20180180. \url{https://doi.org/10.1098/rspb.2018.0180}

\leavevmode\hypertarget{ref-R-tinylabels}{}%
Barth, M. (2022). \emph{tinylabels: Lightweight variable labels}. Retrieved from \url{https://cran.r-project.org/package=tinylabels}

\leavevmode\hypertarget{ref-Chambers2013}{}%
Chambers, C. D. (2013). Registered reports: A new publishing initiative at Cortex. \emph{Cortex}, \emph{49}, 606--610. \url{https://doi.org/10.1016/j.cortex.2012.12.016}

\leavevmode\hypertarget{ref-Chambers2021}{}%
Chambers, C. D., \& Tzavella, L. (2021). The past, present and future of Registered Reports. \emph{Nature Human Behaviour}, 1--14. \url{https://doi.org/10.1038/s41562-021-01193-7}

\leavevmode\hypertarget{ref-Fanelli2010}{}%
Fanelli, D. (2010). "Positive" results increase down the hierarchy of the sciences. \emph{PLoS ONE}, \emph{5}(4), e10068. \url{https://doi.org/10.1371/journal.pone.0010068}

\leavevmode\hypertarget{ref-Fiedler2016}{}%
Fiedler, K., \& Schwarz, N. (2016). Questionable Research Practices Revisited. \emph{Social Psychological and Personality Science}, \emph{7}(1), 45--52. \url{https://doi.org/10.1177/1948550615612150}

\leavevmode\hypertarget{ref-Franco2014}{}%
Franco, A., Malhotra, N., \& Simonovits, G. (2014). Publication bias in the social sciences: Unlocking the file drawer. \emph{Science}, \emph{345}(6203), 1502--1505. \url{https://doi.org/10.1126/science.1255484}

\leavevmode\hypertarget{ref-Franco2016}{}%
Franco, A., Malhotra, N., \& Simonovits, G. (2016). Underreporting in Psychology Experiments: Evidence From a Study Registry. \emph{Social Psychological and Personality Science}, \emph{7}(1), 8--12. \url{https://doi.org/10.1177/1948550615598377}

\leavevmode\hypertarget{ref-Fraser2018}{}%
Fraser, H., Parker, T., Nakagawa, S., Barnett, A., \& Fidler, F. (2018). Questionable research practices in ecology and evolution. \emph{PLOS ONE}, \emph{13}(7), e0200303. \url{https://doi.org/10.1371/journal.pone.0200303}

\leavevmode\hypertarget{ref-Greenwald1975}{}%
Greenwald, A. G. (1975). Consequences of Prejudice Against the Null Hypothesis. \emph{Psychological Bulletin}, \emph{82}(1), 1--20.

\leavevmode\hypertarget{ref-Gross2021}{}%
Gross, K., \& Bergstrom, C. T. (2021). Why ex post peer review encourages high-risk research while ex ante review discourages it. \emph{Proceedings of the National Academy of Sciences}, \emph{118}(51). \url{https://doi.org/10.1073/pnas.2111615118}

\leavevmode\hypertarget{ref-Haaland2019}{}%
Haaland, T. R., Wright, J., \& Ratikainen, I. I. (2019). Bet-hedging across generations can affect the evolution of variance-sensitive strategies within generations. \emph{Proceedings of the Royal Society B}. \url{https://doi.org/10.1098/rspb.2019.2070}

\leavevmode\hypertarget{ref-Hurly2003}{}%
Hurly, A. T. (2003). The twin threshold model: Risk-intermediate foraging by rufous hummingbirds, Selasphorus rufus. \emph{Animal Behaviour}, \emph{66}(4), 751--761. \url{https://doi.org/10.1006/anbe.2003.2278}

\leavevmode\hypertarget{ref-John2012}{}%
John, L. K., Loewenstein, G., \& Prelec, D. (2012). Measuring the Prevalence of Questionable Research Practices With Incentives for Truth Telling. \emph{Psychological Science}, \emph{23}(5), 524--532. \url{https://doi.org/10.1177/0956797611430953}

\leavevmode\hypertarget{ref-Kacelnik1996}{}%
Kacelnik, A., \& Bateson, M. (1996). Risky TheoriesThe Effects of Variance on Foraging Decisions. \emph{Integrative and Comparative Biology}, \emph{36}(4), 402--434. \url{https://doi.org/10.1093/icb/36.4.402}

\leavevmode\hypertarget{ref-Kacelnik1997}{}%
Kacelnik, A., \& Bateson, M. (1997). Risk-sensitivity: Crossroads for theories of decision-making. \emph{Trends in Cognitive Sciences}, \emph{1}(8), 304--309. \url{https://doi.org/10.1016/s1364-6613(97)01093-0}

\leavevmode\hypertarget{ref-Lakens2019b}{}%
Lakens, D. (2019). The value of preregistration for psychological science: A conceptual analysis. \emph{Japanese Psychological Review}, \emph{62}(3), 221--230. \url{https://doi.org/10.24602/sjpr.62.3_221}

\leavevmode\hypertarget{ref-Mahoney1977}{}%
Mahoney, M. J. (1977). Publication Prejudices: An Experimental Study of Confirmatory Bias in the Peer Review System. \emph{Cognitive Therapy and Research}, \emph{1}(2), 161--175. \url{https://doi.org/10.1007/BF01173636}

\leavevmode\hypertarget{ref-Mishra2014}{}%
Mishra, S. (2014). Decision-Making Under Risk: Integrating Perspectives From Biology, Economics, and Psychology. \emph{Personality and Social Psychology Review}, \emph{18}(3), 280--307. \url{https://doi.org/10.1177/1088868314530517}

\leavevmode\hypertarget{ref-R-here}{}%
Müller, K. (2017). \emph{Here: A simpler way to find your files}.

\leavevmode\hypertarget{ref-Muller2014}{}%
Müller, R. (2014). Postdoctoral Life Scientists and Supervision Work in the Contemporary University: A Case Study of Changes in the Cultural Norms of Science. \emph{Minerva}, \emph{52}(3), 329--349. \url{https://doi.org/10.1007/s11024-014-9257-y}

\leavevmode\hypertarget{ref-Nosek2018}{}%
Nosek, B. A., Ebersole, C. R., DeHaven, A. C., \& Mellor, D. T. (2018). The preregistration revolution. \emph{Proceedings of the National Academy of Sciences}, \emph{115}(11), 2600--2606. \url{https://doi.org/10.1073/pnas.1708274114}

\leavevmode\hypertarget{ref-Nosek2022}{}%
Nosek, B. A., Hardwicke, T. E., Moshontz, H., Allard, A., Corker, K. S., Dreber, A., \ldots{} Vazire, S. (2022). Replicability, Robustness, and Reproducibility in Psychological Science. \emph{Annual Review of Psychology}, \emph{73}(1), annurev--psych--020821--114157. \url{https://doi.org/10.1146/annurev-psych-020821-114157}

\leavevmode\hypertarget{ref-R-base}{}%
R Core Team. (2019). \emph{R: A language and environment for statistical computing}. Vienna, Austria: R Foundation for Statistical Computing.

\leavevmode\hypertarget{ref-Rosenthal1979}{}%
Rosenthal, R. (1979). The file drawer problem and tolerance for null results. \emph{Psychological Bulletin}, \emph{86}(3), 638--641. \url{https://doi.org/10.1037/0033-2909.86.3.638}

\leavevmode\hypertarget{ref-RStudioTeam2019}{}%
RStudio Team. (2019). \emph{RStudio: Integrated development environment for r}. Boston, MA: RStudio, Inc.

\leavevmode\hypertarget{ref-Scheel2021}{}%
Scheel, A. M., Schijen, M. R. M. J., \& Lakens, D. (2021). An Excess of Positive Results: Comparing the Standard Psychology Literature With Registered Reports. \emph{Advances in Methods and Practices in Psychological Science}, \emph{4}(2), 251524592110074. \url{https://doi.org/10.1177/25152459211007467}

\leavevmode\hypertarget{ref-Simmons2011}{}%
Simmons, J. P., Nelson, L. D., \& Simonsohn, U. (2011). False-positive psychology: Undisclosed flexibility in data collection and analysis allows presenting anything as significant. \emph{Psychological Science}, \emph{22}(11), 1359--1366. \url{https://doi.org/10.1177/0956797611417632}

\leavevmode\hypertarget{ref-Smaldino2016}{}%
Smaldino, P. E., \& McElreath, R. (2016). The natural selection of bad science. \emph{Royal Society Open Science}, \emph{3}, 160384. \url{https://doi.org/10.1098/rsos.160384}

\leavevmode\hypertarget{ref-Soderberg2021}{}%
Soderberg, C. K., Errington, T. M., Schiavone, S. R., Bottesini, J., Thorn, F. S., Vazire, S., \ldots{} Nosek, B. A. (2021). Initial evidence of research quality of registered reports compared with the standard publishing model. \emph{Nature Human Behaviour}, \emph{5}(8), 990--997. \url{https://doi.org/10.1038/s41562-021-01142-4}

\leavevmode\hypertarget{ref-Sterling1959}{}%
Sterling, T. D. (1959). Publication Decisions and their Possible Effects on Inferences Drawn from Tests of Significanceor Vice Versa. \emph{Journal of the American Statistical Association}, \emph{54}(285), 30--34. \url{https://doi.org/10.1080/01621459.1959.10501497}

\leavevmode\hypertarget{ref-Sterling1995}{}%
Sterling, T. D., Rosenbaum, W. L., \& Weinkam, J. J. (1995). Publication Decisions Revisited: The Effect of the Outcome of Statistical Tests on the Decision to Publish and Vice Versa. \emph{The American Statistician}, \emph{49}(1), 108. \url{https://doi.org/10.2307/2684823}

\leavevmode\hypertarget{ref-vanDalen2012}{}%
van Dalen, H. P., \& Henkens, K. (2012). Intended and unintended consequences of a publish-or-perish culture: A worldwide survey. \emph{Journal of the American Society for Information Science and Technology}, \emph{63}(7), 1282--1293. \url{https://doi.org/10.1002/asi.22636}

\leavevmode\hypertarget{ref-Wacholder2004}{}%
Wacholder, S., Chanock, S., Garcia-Closas, M., El ghormli, L., \& Rothman, N. (2004). Assessing the Probability That a Positive Report is False: An Approach for Molecular Epidemiology Studies. \emph{JNCI Journal of the National Cancer Institute}, \emph{96}(6), 434--442. \url{https://doi.org/10.1093/jnci/djh075}

\leavevmode\hypertarget{ref-Wagenmakers2012}{}%
Wagenmakers, E.-J., Wetzels, R., Borsboom, D., van der Maas, H. L. J., \& Kievit, R. A. (2012). An Agenda for Purely Confirmatory Research. \emph{Perspectives on Psychological Science}, \emph{7}(6), 632--638. \url{https://doi.org/10.1177/1745691612463078}

\leavevmode\hypertarget{ref-R-ggplot2}{}%
Wickham, H. (2016). \emph{Ggplot2: Elegant graphics for data analysis}. Springer-Verlag New York.

\leavevmode\hypertarget{ref-R-stringr}{}%
Wickham, H. (2019). \emph{Stringr: Simple, consistent wrappers for common string operations}. Retrieved from \url{https://CRAN.R-project.org/package=stringr}

\leavevmode\hypertarget{ref-Winterhalder1999}{}%
Winterhalder, B., Lu, F., \& Tucker, B. (1999). Risk-senstive adaptive tactics: Models and evidence from subsistence studies in biology and anthropology. \emph{Journal of Archaeological Research}, \emph{7}(4), 301--348. \url{https://doi.org/10.1007/BF02446047}

\leavevmode\hypertarget{ref-R-knitr}{}%
Xie, Y. (2015). \emph{Dynamic documents with R and knitr} (Second). Boca Raton, Florida: Chapman and Hall/CRC.

\leavevmode\hypertarget{ref-R-bookdown}{}%
Xie, Y. (2016). \emph{Bookdown: Authoring books and technical documents with R markdown}. Boca Raton, Florida: Chapman and Hall/CRC.

\leavevmode\hypertarget{ref-R-rmarkdown}{}%
Xie, Y., Allaire, J., \& Grolemund, G. (2018). \emph{R markdown: The definitive guide}. Boca Raton, Florida: Chapman and Hall/CRC.


\end{document}
